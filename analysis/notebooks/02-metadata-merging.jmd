---
title: "Notebook 2: Working with Metadata"
author: "Kevin Bonham, PhD"
options:
    line_width : 120
    wrap : false
---

In the previous notebook,
we extracted metadata tables from FilemakerPro.
Now, we'll get these into a more usable format for analysis.

## Accessing TOML data in julia

Information about the locations of data are found in `data/data.toml`.
Parsing this file gives a set of nested key:value pairs.

Extra code for much of this analysis is found in the ECHOAnalysis
module in the `src/` directory of this repo.
The docs can be [found here](https://klepac-ceraj-lab.github.io/echo_analysis/dev/).

```julia; results="hidden"
using ECHOAnalysis
```

```julia
using Pkg.TOML: parsefile
mytoml = parsefile("data/data.toml")
keys(mytoml)
```

This is actually already done automatically
when you load the `ECHOAnalysis` module, saved in a variable called `datatoml`.

```julia
# this would throw an error if false
@assert datatoml == mytoml
```

```julia
print(datatoml["description"])
```

The metadata tables are found under `["tables"]["metadata"]`

## Long form data

The `metascrubjl` script generates a table in long-form,
meaning each metadatum has its own row.


```julia
using CSV
using DataFrames
using PrettyTables

# make a formatter for PrettyTables to round long numbers
rounder = Dict(0 => (v,i) -> typeof(v) <: AbstractFloat ? round(v,digits=3) : v)
# set configuration for printing tables
@ptconf formatter = rounder nosubheader=true screen_size=(20,120)

allmeta = CSV.File(datatoml["tables"]["metadata"]["filemakerdb"]["path"]) |> DataFrame

# pretty print table
@pt allmeta
```

Alternatively, we can use the `load_metadata` function.

```julia
allmeta_startup = load_metadata(datatoml, "filemakerdb")

# these would throw errors if false
@assert names(allmeta) == names(allmeta_startup)
@assert size(allmeta) == size(allmeta_startup)
```

The script tries to find `timepoint` values for everything, and if it can't,
it assumes that the matadatum applies to all timepoints for that subject.
These are marked with `timepoint = 0`.
Let's look at which variables that applies to:

```julia
allmeta[allmeta.timepoint .== 0, :parent_table] |> unique
```

Those all look reasonable!
Well, except for `WeightHeight`,
which is for some reason part of a table that is not timepoint associated.
But `childHeight` and `childWeight`
are found in a different table, so we'll just ignore this one.

## Sample Metadata

In addition to the FilemakerPro database,
we also have metdata info stored for each of the samples that are processed.
In this case, `timepoint` and `subject` do not uniquely identify samples,
since we can have multiple samples per timepoint.
`sample` IDs should be unique though.

```julia; results="hidden"
samples = load_metadata(datatoml, "samples")
rename!(samples, [:TimePoint=>:timepoint, :DOC=>:date, :SubjectID=>:subject, :SampleID=>:sample])

# convert to longform
samples = melt(samples, [:subject, :timepoint, :sample], variable_name=:metadatum)
dropmissing!(samples, [:subject, :sample])
samples[!, :parent_table] .= "FecalProcessing"
```

## Brain Data

Finally, we also have tables of brain volumes for many of our subjects.

```julia
brainfiles = datatoml["tables"]["brain"]
brainvol = CSV.read(brainfiles["gross_volumes"]["path"])

# remove spaces from columns names
names!(brainvol, map(names(brainvol)) do n
                        replace(String(n), " "=>"_") |> lowercase |> Symbol
                    end)
rename!(brainvol, :study_id => :subject)

# Convert to longform
brainvol = stack(brainvol, [:white_matter_volume, :grey_matter_volume, :csf_volume], :subject, variable_name=:metadatum)
@pt brainvol
```

We need to fix the subjects - the letters represent timepoints -
using the `resolve_letter_timepoint` function.

```julia
# convert letter timepoint into number
brainsid = resolve_letter_timepoint(brainvol.subject)
brainsid[1:5]
```

```julia
brainvol.subject = getfield.(brainsid, :subject)
brainvol.timepoint = getfield.(brainsid, :timepoint)
brainvol.sample = getfield.(brainsid, :sample)
# This uses slightly different syntax, because the column doesn't exist.
# The `.=` broadcast assigment makes every row in the column the same string
brainvol[!, :parent_table] .= "brainVolume"

@pt brainvol
```

And now the same thing for the high resolution scan table:

```julia; results="hidden"
hires = CSV.read(brainfiles["hires"]["path"])

rename!(hires, Dict(:ID=>:subject, :Timepoint=>:timepoint))
# don't want to replicate :age column
select!(hires, Not(:Age))
@pt hires
```

There are a lot of individual brain regions that are separated in this table,
and the right and left hemispheres are distinguished.
For the most part, we're not going to need this level of specificity,
but we can group individual brain regions
and combine left / right hemispheres.
I'll also make a column with the total brain volume for later normalization.

```julia

```


```julia
# convert to longform
hires = melt(hires, [:subject, :timepoint], variable_name=:metadatum)
hires[!, :parent_table] .= "corticalVolumes"
```

We can only concatenate tables if they all have the same columns,
so I'll add a `sample` ID to all of the other observations
to match what's in `samples`.
The fecal sample `sample` IDs are build from the `subject` ID and `timepoint`,
so I'll do the same for other observations.

_Note_: Fecal sample `sample` IDs are built as follows...

```
C0596_1F_1A
C = Child (or M = Mother)
0596 = SubjectID
1 = TimePoint (converted from A=1, B=2, etc.)
F = Fecal i.e. Genotek sample (or E = ethanol sample)
1 = CollectionRep (if multiple samples for same TimePoint)
A = AliquotRep (each fecal Genotek sample is aliquoted into 2 or 4 smaller cryovials)
    A,B or A,B,C,D ; SOP is to process AliquotRep A for DNA extractions
```

```julia; results="hidden"
allmeta[!,:sample] = map(r->
        "C" * lpad(string(r[:subject]), 4, "0") * "_$(Int(floor(r[:timepoint])))M",
        eachrow(allmeta))

brainvol[!,:sample] = map(r->
        "C" * lpad(string(r[:subject]), 4, "0") * "_$(Int(floor(r[:timepoint])))M",
        eachrow(brainvol))

hires[!,:sample] = map(r->
        "C" * lpad(string(r[:subject]), 4, "0") * "_$(Int(floor(r[:timepoint])))M",
        eachrow(hires))

```

And then concatenate all the tables together

```julia
allmeta = vcat(allmeta, brainvol, hires, samples)
# reorder columns
allmeta = allmeta[!,[:sample, :subject, :timepoint, :metadatum, :value, :parent_table]]
# remove rows with missing values
dropmissing!(allmeta)

# show a random assortment of ~ 10 rows
@pt randrows(allmeta)
```

```julia
CSV.write(datatoml["tables"]["metadata"]["all"]["path"], allmeta);
@assert isfile(datatoml["tables"]["metadata"]["all"]["path"])
```
