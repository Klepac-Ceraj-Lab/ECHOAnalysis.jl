---
title: "Notebook 2: Working with Metadata"
author: "Kevin Bonham, PhD"
options:
    line_width : 120
    wrap : false
---

In the previous notebook,
we extracted metadata tables from FilemakerPro.
Now, we'll get these into a more usable format for analysis.

## Accessing TOML data in julia

Information about the locations of data are found in `data/data.toml`.
Parsing this file gives a set of nested key:value pairs.

Extra code for much of this analysis is found in the ECHOAnalysis
module in the `src/` directory of this repo.
The docs can be [found here](https://klepac-ceraj-lab.github.io/echo_analysis/dev/).

```julia; results="hidden"
using ECHOAnalysis
```

```julia
using Pkg.TOML: parsefile
mytoml = parsefile("data/data.toml")
keys(mytoml)
```

This is actually already done automatically
when you load the `ECHOAnalysis` module, saved in a variable called `datatoml`.

```julia
# this would throw an error if false
@assert datatoml == mytoml
```

```julia
print(datatoml["description"])
```

The metadata tables are found under `["tables"]["metadata"]`

## Long form data

The `metascrubjl` script generates a table in long-form,
meaning each metadatum has its own row.


```julia
using CSV
using DataFrames
using PrettyTables

# make a formatter for PrettyTables to round long numbers
rounder = Dict(0 => (v,i) -> typeof(v) <: AbstractFloat ? round(v,digits=3) : v)
# set configuration for printing tables
@ptconf formatter = rounder nosubheader=true screen_size=(20,120)

allmeta = CSV.File(datatoml["tables"]["metadata"]["filemakerdb"]["path"]) |> DataFrame
# pretty print table
@pt allmeta
```

Alternatively, we can use the `load_metadata` function.

```julia
allmeta_startup = load_metadata(datatoml, "filemakerdb")

# these would throw errors if false
@assert names(allmeta) == names(allmeta_startup)
@assert size(allmeta) == size(allmeta_startup)
```

The script tries to find `timepoint` values for everything, and if it can't,
it assumes that the matadatum applies to all timepoints for that subject.
These are marked with `timepoint = 0`.
Let's look at which variables that applies to:

```julia
allmeta[allmeta.timepoint .== 0, :parent_table] |> unique
```

Those all look reasonable!
Well, except for `WeightHeight`,
which is for some reason part of a table that is not timepoint associated.
But `childHeight` and `childWeight`
are found in a different table, so we'll just ignore this one.

### Summaries and transforms

There are a few bits of metadata where it's useful
to have a summary or a slightly transformed version.
One example of this is age -
For reasons that will be clear later,
it's useful to group gids by age groups:

- under 1 year old
- between 1 and 2 years old
- over 2 years old


```julia
using Statistics
agelabels = by(allmeta, [:subject, :timepoint]) do sample
    age = filter(row-> row.metadatum == "correctedAgeDays", sample)
    if nrow(age) > 0
        years = mean(parse.(Int, skipmissing(age.value))) / 365

        if ismissing(years)
            label=missing
        elseif years <= 1
            label="1 and under"
        elseif 1 < years < 2
            label="1 to 2"
        else
            label="2 and over"
        end
    else
        label=missing
    end
    return DataFrame(
            metadatum="ageLabel",
            value=label,
            parent_table="Calculated"
            )
end
dropmissing!(agelabels)
@pt randrows(agelabels[.!ismissing.(agelabels.value), :])
```
```julia; results="hidden"
# add to main metadata dataframe
append!(allmeta, agelabels)
```

For cognitive scores (eg. Mullen),
we want to use a normalized score that's comparable across tests.


```julia
cogcols = [
    "languageComposite", # this is from Bayleys
    "motorComposite", # also Bayleys
    "mullen_EarlyLearningComposite",
    "fullScaleComposite", # this is from WSSPI
    "FSIQ_Composite",  # this is from WISC
    ]
cogscores = by(allmeta, [:subject, :timepoint]) do sample
    cogs = filter(row-> in(row.metadatum, cogcols) &&
                        !ismissing(row.value),
                    sample)
    if nrow(cogs) > 0
        parent = cogs.parent_table[1]
        if parent == "Bayley's"
            nrow(cogs) != 2 && throw(ErrorException("Wrong number of rows for $parent"))
            assessment = "Bayleys"
            score = string(mean(parse.(Float64, cogs.value)))
        else
            nrow(cogs) != 1 && throw(ErrorException("Wrong number of rows for $parent"))
            metadatum = cogs.metadatum[1]
            if metadatum == "mullen_EarlyLearningComposite"
                assessment = "Mullen"
            elseif metadatum == "fullScaleComposite"
                assessment = "WSSPI"
            elseif metadatum == "FSIQ_Composite"
                assessment = "WISC"
            else
                throw(ErrorException("Couldn't figure out assessment $metadatum"))
            end
            score = cogs.value[1]
        end
    else
        assessment = missing
        score = missing
    end
    return DataFrame(metadatum    = ["cogAssessment", "cogScore"],
                     value        = [assessment,      score],
                     parent_table = ["Calculated",    "Calculated"])
end

dropmissing!(cogscores)
@pt randrows(cogscores[.!ismissing.(cogscores.value), :])
```
```julia; results="hidden"
# add to main metadata dataframe
append!(allmeta, cogscores)
```


## Sample Metadata

In addition to the FilemakerPro database,
we also have metdata info stored for each of the samples that are processed.
In this case, `timepoint` and `subject` do not uniquely identify samples,
since we can have multiple samples per timepoint.
`sample` IDs should be unique though.

```julia; results="hidden"
samples = load_metadata(datatoml, "samples")
rename!(samples, [:TimePoint=>:timepoint, :DOC=>:date, :SubjectID=>:subject, :SampleID=>:sample])

# convert to longform
samples = melt(samples, [:subject, :timepoint, :sample], variable_name=:metadatum)
dropmissing!(samples, [:subject, :sample])
samples[!, :parent_table] .= "FecalProcessing"
```
Finally, we want to make sure the maternal samples
also have a value for `ageLabel`.

```julia
momlabels = by(samples, [:subject, :timepoint]) do sample
    if any(s-> startswith(s, "M"), skipmissing(sample.sample))
        outdf = filter(row-> !ismissing(row.sample) && startswith(row.sample, "M"), sample)
        outdf.metadatum .= :ageLabel
        outdf.value .= "mom"
        outdf.parent_table .= "Calculated"
    else
        outdf = DataFrame(first(sample))

    end
    return unique(outdf[:, [:metadatum, :value, :parent_table, :sample]])
end
filter!(row-> row.value == "mom", momlabels)
@pt randrows(momlabels[.!ismissing.(momlabels.value), :])

```
```julia; results="hidden"
# add to main sample dataframe (while reordering columns)
append!(samples, momlabels[names(samples)])
```


## Brain Data

We also have tables of brain volumes for many of our subjects.

```julia
brainfiles = datatoml["tables"]["brain"]
brainvol = CSV.read(brainfiles["gross_volumes"]["path"])

# remove spaces from columns names
names!(brainvol, map(names(brainvol)) do n
                        replace(String(n), " "=>"_") |> lowercase |> Symbol
                    end)
rename!(brainvol, :study_id => :subject)

# Convert to longform
brainvol = stack(brainvol, [:white_matter_volume, :grey_matter_volume, :csf_volume], :subject, variable_name=:metadatum)
@pt brainvol
```

We need to fix the subjects - the letters represent timepoints -
using the `resolve_letter_timepoint` function.

```julia
# convert letter timepoint into number
brainsid = resolve_letter_timepoint(brainvol.subject)
brainsid[1:5]
```

```julia
brainvol.subject = getfield.(brainsid, :subject)
brainvol.timepoint = getfield.(brainsid, :timepoint)
brainvol.sample = getfield.(brainsid, :sample)
# This uses slightly different syntax, because the column doesn't exist.
# The `.=` broadcast assigment makes every row in the column the same string
brainvol[!, :parent_table] .= "brainVolume"

@pt brainvol
```

And now the same thing for the high resolution scan table:

```julia; results="hidden"
hires = CSV.read(brainfiles["hires"]["path"])

rename!(hires, Dict(:ID=>:subject, :Timepoint=>:timepoint))
# don't want to replicate :age column
select!(hires, Not(:Age))
@pt hires
```

There are a lot of individual brain regions that are separated in this table,
and the right and left hemispheres are distinguished.
For the most part, we're not going to need this level of specificity,
but we can group individual brain regions
and combine left / right hemispheres.
I'll also make a column with the total brain volume for later normalization.

```julia
mapping = CSV.read("data/brain/brain_region_key.csv")
@pt mapping
```
```julia
hires.hires_total = [sum(row[3:end]) for row in eachrow(hires)]

cols_seen = let ns = lowercase.(String.(names(hires)))
    cols_seen = Int[]
    by(mapping, :region) do region
        fs = lowercase.(region.feature)
        cols = findall(n-> any(f-> occursin(f, n), fs), ns)
        append!(cols_seen, cols)
        hires[!, Symbol(first(region.region))] = [sum(row[cols]) for row in eachrow(hires)]
    end
    cols_seen
end
```



```julia
# convert to longform
hires = melt(hires, [:subject, :timepoint], variable_name=:metadatum)
hires[!, :parent_table] .= "hiresVolumes"
```

We can only concatenate tables if they all have the same columns,
so I'll add a `sample` ID to all of the other observations
to match what's in `samples`.
The fecal sample `sample` IDs are build from the `subject` ID and `timepoint`,
so I'll do the same for other observations.

_Note_: Fecal sample `sample` IDs are built as follows...

```
C0596_1F_1A
C = Child (or M = Mother)
0596 = SubjectID
1 = TimePoint (converted from A=1, B=2, etc.)
F = Fecal i.e. Genotek sample (or E = ethanol sample)
1 = CollectionRep (if multiple samples for same TimePoint)
A = AliquotRep (each fecal Genotek sample is aliquoted into 2 or 4 smaller cryovials)
    A,B or A,B,C,D ; SOP is to process AliquotRep A for DNA extractions
```

```julia; results="hidden"
allmeta[!,:sample] = map(r->
        "C" * lpad(string(r[:subject]), 4, "0") * "_$(Int(floor(r[:timepoint])))M",
        eachrow(allmeta))

brainvol[!,:sample] = map(r->
        "C" * lpad(string(r[:subject]), 4, "0") * "_$(Int(floor(r[:timepoint])))M",
        eachrow(brainvol))

hires[!,:sample] = map(r->
        "C" * lpad(string(r[:subject]), 4, "0") * "_$(Int(floor(r[:timepoint])))M",
        eachrow(hires))

```

And then concatenate all the tables together

```julia
allmeta = vcat(allmeta, brainvol, hires, samples)
# reorder columns
allmeta = allmeta[!,[:sample, :subject, :timepoint, :metadatum, :value, :parent_table]]
# remove rows with missing values
dropmissing!(allmeta)

# show a random assortment of ~ 10 rows
@pt randrows(allmeta)
```
