# Quality control of metagenomes

All of the metagenomes were processed
using tools from the [bioBakery](https://bitbucket.org/biobakery/biobakery/wiki/Home).

```julia; echo=false; results="hidden"
ENV["GKSwstype"] = "100" # hide
```

```julia; echo=false; results="hidden"
using ECHOAnalysis
using CSV, DataFrames
using DataFramesMeta;

outpath, figures = notebookpaths!(4)
```

## Quality control

First, I'll look at the QC results from `kneaddata`.

```julia
qc_files = let qcfiles=[]
    for (root, dirs, files) in walkdir(datatoml["tables"]["biobakery"]["path"])
        occursin("kneaddata", root) || continue
        filter!(files) do f
            occursin("read_counts", f)
        end
        append!(qcfiles, joinpath.(root, files))
    end
    qcfiles
end

# make a DataFrame of the qc table from the first batch
qc = CSV.read(qc_files[1])
qc[:batch] = "batch001"

# loop through the rest and concatenate to the first one
for f in qc_files[2:end]
    df = CSV.read(f)
    # get batch name from file
    df[:batch] = match(r"(batch\d+)", f).captures[1]
    global qc = vcat(qc, df)
end

randrows(first(qc, 15))
```

To keep the formatting of sample IDs consistant across data types,
I'll use the `resolve_sampleID` function.


```julia
qc[:Sample] = map(qc[:Sample]) do s
    s = replace(s, "_kneaddata"=> "")
    resolve_sampleID(s)[:sample]
end

randrows(first(qc,5))
```

```julia
# cleaning up the column names a bit
names!(qc,
    map(n-> Symbol(replace(String(n), " "=>"_")),
    names(qc)))
randrows(first(qc,5))
```

I don't really care about each mate pair individually,
so I'll sum them up

```julia
qc = @linq qc |>
  transform(raw = :raw_pair1 .+ :raw_pair2,
            trimmed = :trimmed_pair1 .+ :trimmed_pair2,
            orphan = :final_orphan1 .+ :final_orphan2,
            final = :final_pair1 .+ :final_pair2,
            )
randrows(qc[[:Sample, :batch, :raw, :trimmed, :orphan, :final]])
```

Now let's take a look at them with some plots.

```julia
using StatsPlots

sort!(qc, [:batch, :raw])

bar(x=qc[:Sample], hcat(qc[:raw], qc[:final]),
    xaxis="Samples", yaxis= "Count", legend=:topleft,
    title = "QC from Kneaddata", label=["Raw" "Final"],
    linecolor=:match)

```

```julia; echo=false; results="hidden"
savefig(joinpath(figures, "knead-qc.svg"))
```

These are a little more variable than I'd like.
Let's take a look at their properties:

```julia
using Statistics

qc_stats = by(qc, :batch) do df
                DataFrame(
                  mean = round(mean(df[:final]) / 1e6, digits=2),
                  med  = round(median(df[:final]) / 1e6, digits=2),
                  max  = round(maximum(df[:final]) / 1e6, digits=2),
                  min  = round(minimum(df[:final]) / 1e6, digits=2),
                  )
end
CSV.write(joinpath(outpath, "qc_stats.csv"), qc_stats)
randrows(qc_stats)
```

According to Andre Comeau of [Integrated Microbiome Research](http://www.imr.bio)
(where our sequencing is done):

> However, even with sample normalization, the best value that kits/protocols can obtain is about a 2-fold difference from the mean...which then means if your average # of reads is, for example, 8 M, then you'll see samples up to 2-fold higher and 2-fold lower at max = about 4-16 M range.
>
> Now added on top of that is that each NextSeq run is independent and the loading (cluster density, which is a bit of an art) tends to vary a little bit, so overall output per sample also varies there too, but usually within a tighter "true" 2-fold range. Hence this explains a bunch of the variation.
