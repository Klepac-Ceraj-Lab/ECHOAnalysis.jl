---
title: "Notebook 2: Working with Metadata"
author: "Kevin Bonham, PhD"
options:
    line_width : 120
    wrap : false
---

In the previous notebook, we generated separate metadata files
for different tables in the FilemakerPro database.
Now, we'll get these into a more usable format for analysis.

## Accessing TOML data in julia

Information about the locations of data are found in `data/data.toml`.
Parsing this file gives a set of nested key:value pairs.

```julia; echo=false; results="hidden"
using ECHOAnalysis
```

```julia
using Pkg.TOML: parsefile
files = parsefile("data/data.toml")
keys(files)
```

```julia
print(files["description"])
```

The metadata tables are found under `["tables"]["metadata"]`

## Long form data

The `metascrubjl` script generates a table in long-form,
meaning each metadatum has its own row.


```julia
using CSV
using DataFrames
using PrettyTables

# make a formatter for PrettyTables to round long numbers
rounder = Dict(0 => (v,i) -> typeof(v) <: AbstractFloat ? round(v,digits=3) : v)
# set configuration for printing tables
@ptconf formatter = rounder nosubheader=true screen_size=(20,120)

allmeta = CSV.File(files["tables"]["metadata"]["filemakerdb"]["path"]) |> DataFrame

# pretty print table
@pt allmeta
```

Alternatively, we can use the `load_metadata` function.

```julia
allmeta_startup = load_metadata(files, "filemakerdb")

# these would throw errors if false
@assert names(allmeta) == names(allmeta_startup)
@assert size(allmeta) == size(allmeta_startup)
```

The script tries to find `timepoint` values for everything, and if it can't,
it assumes that the matadatum applies to all timepoints for that subject.
These are marked with `timepoint = 0`.
Let's look at which variables that applies to:

```julia
allmeta[allmeta.timepoint .== 0, :parent_table] |> unique
```

Those all look reasonable!
Well, except for `WeightHeight`,
which is for some reason part of a table that is not timepoint associated.
But `childHeight` and `childWeight`
are found in a different table, so we'll just ignore this one.

## Sample Metadata

In addition to the FilemakerPro database,
we also have metdata info stored for each of the samples that are processed.
In this case, `timepoint` and `studyID` do not uniquely identify samples,
since we can have multiple samples per timepoint.
`sampleID`s should be unique though.

```julia; results="hidden"
samples = load_metadata(files, "samples")
rename!(samples, [:TimePoint=>:timepoint, :DOC=>:date, :SubjectID=>:studyID, :SampleID=>:sampleID])

# convert to longform
samples = melt(samples, [:studyID, :timepoint, :sampleID], variable_name=:metadatum)
dropmissing!(samples, [:studyID, :sampleID])
samples[!, :parent_table] .= "FecalProcessing"
```

## Brain Data

Finally, we also have tables of brain volumes for many of our subjects.

```julia
brainfiles = files["tables"]["brain"]
brainvol = CSV.read(brainfiles["gross_volumes"]["path"])

# remove spaces from columns names
names!(brainvol, map(names(brainvol)) do n
                        replace(String(n), " "=>"_") |> lowercase |> Symbol
                    end)
rename!(brainvol, :study_id => :studyID)

# Convert to longform
brainvol = stack(brainvol, [:white_matter_volume, :grey_matter_volume, :csf_volume], :studyID, variable_name=:metadatum)
@pt brainvol
```

We need to fix the studyIDs - the letters represent timepoints -
using the `resolve_letter_timepoint` function.

```julia
# convert letter timepoint into number
brainsid = resolve_letter_timepoint.(brainvol.studyID)
brainsid[1:5]
```

```julia
brainvol[!, :studyID] = getfield.(brainsid, :subject)
brainvol[!, :timepoint] = getfield.(brainsid, :timepoint)
brainvol[!, :sampleID] = getfield.(brainsid, :sample)
brainvol[!, :parent_table] .= "brainVolume"

@pt brainvol
```

And now the same thing for the cortical and subcortical volume tables:

```julia; results="hidden"
cortical = CSV.read(brainfiles["cortical"]["path"])
subcortical = CSV.read(brainfiles["subcortical"]["path"])

corticalids = resolve_letter_timepoint.(cortical[!, :SubjID])
cortical[!, :studyID] = getfield.(corticalids, :subject)
cortical[!, :timepoint] = getfield.(corticalids, :timepoint)

# we only care about a subset of values for now
cortical = cortical[:, [:studyID, :timepoint, :LThickness, :RThickness,
                                           :LSurfArea,  :RSurfArea,
                                           :ICV]]

# convert to longform
cortical = melt(cortical, [:studyID, :timepoint], variable_name=:metadatum)
cortical[!, :parent_table] .= "corticalVolumes"

# for the subcortex we mostly care about the total volume rather than individual values
subcortical[!, :subcortical_volume] = map(row-> sum(Vector(row[2:end-1])), eachrow(subcortical))

subcorticalids = resolve_letter_timepoint.(subcortical[!,:SubjID])
subcortical[!,:studyID] = getfield.(subcorticalids, :subject)
subcortical[!,:timepoint] = getfield.(subcorticalids, :timepoint)
subcortical = subcortical[!,[:studyID, :timepoint, :subcortical_volume]]

# convert to longform
subcortical = melt(subcortical, [:studyID, :timepoint], variable_name=:metadatum)
subcortical[!,:parent_table] .= "subcorticalVolumes"
```

We can only concatenate tables if they all have the same columns,
so I'll add a `sampleID` to all of the other observations
to match what's in `samples`.
The fecal sample `sampleID`s are build from the subjectID and timepoint,
so I'll do the same for other observations.

_Note_: Fecal sample `sampleID`s are built as follows...

```
C0596_1F_1A
C = Child (or M = Mother)
0596 = SubjectID
1 = TimePoint (converted from A=1, B=2, etc.)
F = Fecal i.e. Genotek sample (or E = ethanol sample)
1 = CollectionRep (if multiple samples for same TimePoint)
A = AliquotRep (each fecal Genotek sample is aliquoted into 2 or 4 smaller cryovials)
    A,B or A,B,C,D ; SOP is to process AliquotRep A for DNA extractions
```

```julia; results="hidden"
allmeta[!,:sampleID] = map(r->
        "C" * lpad(string(r[:studyID]), 4, "0") * "_$(Int(floor(r[:timepoint])))M",
        eachrow(allmeta))

brainvol[!,:sampleID] = map(r->
        "C" * lpad(string(r[:studyID]), 4, "0") * "_$(Int(floor(r[:timepoint])))M",
        eachrow(brainvol))

cortical[!,:sampleID] = map(r->
        "C" * lpad(string(r[:studyID]), 4, "0") * "_$(Int(floor(r[:timepoint])))M",
        eachrow(cortical))

subcortical[!,:sampleID] = map(r->
        "C" * lpad(string(r[:studyID]), 4, "0") * "_$(Int(floor(r[:timepoint])))M",
        eachrow(subcortical))
```

And then concatenate all the tables together

```julia
allmeta = vcat(allmeta, brainvol, cortical, subcortical, samples)
# reorder columns
allmeta = allmeta[!,[:sampleID, :studyID, :timepoint, :metadatum, :value, :parent_table]]
# remove rows with missing values
dropmissing!(allmeta)

# show a random assortment of ~ 10 rows
@pt randrows(allmeta)
```

```julia
CSV.write(files["tables"]["metadata"]["all"]["path"], allmeta);
@assert isfile(files["tables"]["metadata"]["all"]["path"])
```
