# Working with Metadata

In the previous notebook, we generated separate metadata files
for different tables in the FilemakerPro database.
Now, we'll get these into a more usable format for analysis.

## Accessing TOML data in julia

Information about the locations of data are found in `data/data.toml`.
Parsing this file gives a set of nested key:value pairs.

```julia
cd(dirname(@__FILE__))
using ECHOAnalysis # hide
```

```julia
using Pkg.TOML: parsefile
files = parsefile("../../data/data.toml")
println.(keys(files))
```

```julia
@show files["description"]
```

The metadata tables are found under `["tables"]["metadata"]`

## Long form data

The `metascrubjl` script generates a table in long-form,
meaning each metadatum has its own row.


```julia
using CSV
using DataFrames
using PrettyTables

allmeta = CSV.File(files["tables"]["metadata"]["filemakerdb"]["path"]) |> DataFrame

# show ~10 random rows
allmeta[rand(nrow(allmeta)) .< 10 / nrow(allmeta), :] |> pretty_table
```

Alternatively, we can use the [`load_metadata`](@ref) function.

```julia
allmeta_startup = load_metadata(files, "filemakerdb")
@assert names(allmeta) == names(allmeta_startup)
@assert size(allmeta) == size(allmeta_startup)
```

The script tries to find `timepoint` values for everything, and if it can't,
it assumes that the matadatum applies to all timepoints for that subject.
These are marked with `timepoint = 0`.
Let's look at which variables that applies to:

```julia
@show allmeta[allmeta[:timepoint] .== 0, :parent_table] |> unique
```

Those all look reasonable!

## Sample Metadata

In addition to the FilemakerPro database,
we also have metdata info stored for each of the samples that are processed.
In this case, `timepoint` and `studyID` do not uniquely identify samples,
since we can have multiple samples per timepoint.
`sampleID`s should be unique though.

```julia
samples = load_metadata(files, "samples")
rename!(samples, [:TimePoint=>:timepoint, :DOC=>:date, :SubjectID=>:studyID, :SampleID=>:sampleID])

# convert to longform
samples = melt(samples, [:studyID, :timepoint, :sampleID], variable_name=:metadatum)
samples = filter(r-> !any(ismissing, [r[:studyID], r[:sampleID]]), samples)
disallowmissing!(samples)
samples[:parent_table] = "FecalProcessing";
```

## Brain Data

Finally, we also have tables of brain volumes for many of our subjects.

```julia
brainfiles = files["tables"]["brain"]
brainvol = CSV.read(brainfiles["gross_volumes"]["path"])

# remove spaces from columns names
names!(brainvol, map(names(brainvol)) do n
                        replace(String(n), " "=>"_") |> lowercase |> Symbol
                    end)
rename!(brainvol, :study_id => :studyID)

# Convert to longform
brainvol = stack(brainvol, [:white_matter_volume, :grey_matter_volume, :csf_volume], :studyID, variable_name=:metadatum)
pretty_table(brainvol)
```

We need to fix the studyIDs - the letters represent timepoints -
using the [`resolve_letter_timepoint`](@ref) function.

```julia
# convert letter timepoint into number
brainsid = resolve_letter_timepoint.(brainvol[:studyID])
brainsid[1:5]
```

```julia
brainvol[:studyID] = getfield.(brainsid, :subject)
brainvol[:timepoint] = getfield.(brainsid, :timepoint)
brainvol[:sampleID] = getfield.(brainsid, :sample)
brainvol[:parent_table] = "brainVolume"

pretty_table(brainvol)
```

And now the same thing for the cortical and subcortical volume tables:

```julia
cortical = CSV.read(brainfiles["cortical"]["path"])
subcortical = CSV.read(brainfiles["subcortical"]["path"])

corticalids = resolve_letter_timepoint.(cortical[:SubjID])
cortical[:studyID] = getfield.(corticalids, :subject)
cortical[:timepoint] = getfield.(corticalids, :timepoint)

# we only care about a subset of values for now
cortical = cortical[[:studyID, :timepoint, :LThickness, :RThickness,
                                           :LSurfArea,  :RSurfArea,
                                           :ICV]]

# convert to longform
cortical = melt(cortical, [:studyID, :timepoint], variable_name=:metadatum)
cortical[:parent_table] = "corticalVolumes"

# for the subcortex we mostly care about the total volume rather than individual values
subcortical[:subcortical_volume] = map(row-> sum(Vector(row[2:end-1])), eachrow(subcortical))

subcorticalids = resolve_letter_timepoint.(subcortical[:SubjID])
subcortical[:studyID] = getfield.(subcorticalids, :subject)
subcortical[:timepoint] = getfield.(subcorticalids, :timepoint)
subcortical = subcortical[[:studyID, :timepoint, :subcortical_volume]]

# convert to longform
subcortical = melt(subcortical, [:studyID, :timepoint], variable_name=:metadatum)
subcortical[:parent_table] = "subcorticalVolumes"
```

We can only concatenate tables if they all have the same columns,
so I'll add a `sampleID` to all of the other observations
to match what's in `samples`.
The fecal sample `sampleID`s are build from the subjectID and timepoint,
so I'll do the same for other observations

```julia
allmeta[:sampleID] = map(r->
        "C" * lpad(string(r[:studyID]), 4, "0") * "_$(Int(floor(r[:timepoint])))M",
        eachrow(allmeta))

brainvol[:sampleID] = map(r->
        "C" * lpad(string(r[:studyID]), 4, "0") * "_$(Int(floor(r[:timepoint])))M",
        eachrow(brainvol))

cortical[:sampleID] = map(r->
        "C" * lpad(string(r[:studyID]), 4, "0") * "_$(Int(floor(r[:timepoint])))M",
        eachrow(cortical))

subcortical[:sampleID] = map(r->
        "C" * lpad(string(r[:studyID]), 4, "0") * "_$(Int(floor(r[:timepoint])))M",
        eachrow(subcortical))
```

And then concatenate all the tables together

```julia
allmeta = vcat(allmeta, brainvol, cortical, subcortical, samples)
# reorder columns
allmeta = allmeta[[:sampleID, :studyID, :timepoint, :metadatum, :value, :parent_table]]
# remove rows with missing values
filter!(r-> !any(ismissing, [r[:studyID], r[:sampleID], r[:timepoint], r[:metadatum]]), allmeta)
disallowmissing!(allmeta)

# show a random assortment of ~ 10 rows
allmeta[rand(nrow(allmeta)) .< 10 / nrow(allmeta), :] |> pretty_table
```

A some of the `:value` fields have quotes or newlines in the field,
which screws up parsing later. For now I will just replace them.

```julia
for i in eachindex(allmeta[:value])
    v = allmeta[i, :value]
    ismissing(v) && continue
    if isa(v, AbstractString) && occursin(r"\n", v)
        v = replace(v, r"\n"=>"___")
        allmeta[i, :value] = v
    elseif isa(v, AbstractString) && occursin(r"\"", v)
        v = replace(v, r"\""=>"'")
        allmeta[i, :value] = v
    end
end


CSV.write(files["tables"]["metadata"]["all"]["path"], allmeta);
@assert isfile(files["tables"]["metadata"]["all"]["path"]); nothing # hide
```
